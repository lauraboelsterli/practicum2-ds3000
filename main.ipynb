{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1\n",
    "The goal is to analyze the FAA Wildlife Strike Database to identify patterns and trends in wildlife\n",
    "strikes to civil aircraft. We must clean and reduce the dataset to only include relevant features for\n",
    "the analysis. We must examine factors such as aircraft type, wildlife involved, location, and time.\n",
    "After extracting factors like these we perform statistical tests, test hypotheses, and create visualizations\n",
    "to help reduce the occurance and impact of wildlife strikes on civil aircraft in the future."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the data using pandas and inspect it.\n",
    "\n",
    "Perform the initial inspection of the data, its shape, types, etc.\n",
    "\n",
    "Evaluate the dataset and perform at least three type of data preparation and justify the approach that is taken to prepare the data for analysis. Data prep can include, but is not limited to: handling missing values, data types, duplicates, etc. You will need to ensure that your data preparation addressed issues in at least 7 fields in the data.\n",
    "\n",
    "Prepare meaningful* summary statistics for 3 continuous variables and 3 categorical variables.\n",
    "Note: meaningful summary statistics explains the statistical summary of relevant fields in a coherent manner."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-24T21:25:11.219900Z",
     "start_time": "2025-10-24T21:25:11.086041Z"
    }
   },
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from scipy import stats\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "from scipy.stats import skew\n",
    "data = pd.read_csv(\"Bird_Strikes_1990_2023.csv\")\n",
    "data"
   ],
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Bird_Strikes_1990_2023.csv'",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mFileNotFoundError\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[5]\u001B[39m\u001B[32m, line 6\u001B[39m\n\u001B[32m      4\u001B[39m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mmatplotlib\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mpyplot\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mas\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mplt\u001B[39;00m\n\u001B[32m      5\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01msklearn\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mlinear_model\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m LinearRegression\n\u001B[32m----> \u001B[39m\u001B[32m6\u001B[39m data = \u001B[43mpd\u001B[49m\u001B[43m.\u001B[49m\u001B[43mread_csv\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mBird_Strikes_1990_2023.csv\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[32m      7\u001B[39m data\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001B[39m, in \u001B[36mread_csv\u001B[39m\u001B[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001B[39m\n\u001B[32m   1013\u001B[39m kwds_defaults = _refine_defaults_read(\n\u001B[32m   1014\u001B[39m     dialect,\n\u001B[32m   1015\u001B[39m     delimiter,\n\u001B[32m   (...)\u001B[39m\u001B[32m   1022\u001B[39m     dtype_backend=dtype_backend,\n\u001B[32m   1023\u001B[39m )\n\u001B[32m   1024\u001B[39m kwds.update(kwds_defaults)\n\u001B[32m-> \u001B[39m\u001B[32m1026\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_read\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfilepath_or_buffer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001B[39m, in \u001B[36m_read\u001B[39m\u001B[34m(filepath_or_buffer, kwds)\u001B[39m\n\u001B[32m    617\u001B[39m _validate_names(kwds.get(\u001B[33m\"\u001B[39m\u001B[33mnames\u001B[39m\u001B[33m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m))\n\u001B[32m    619\u001B[39m \u001B[38;5;66;03m# Create the parser.\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m620\u001B[39m parser = \u001B[43mTextFileReader\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfilepath_or_buffer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    622\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m chunksize \u001B[38;5;129;01mor\u001B[39;00m iterator:\n\u001B[32m    623\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m parser\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001B[39m, in \u001B[36mTextFileReader.__init__\u001B[39m\u001B[34m(self, f, engine, **kwds)\u001B[39m\n\u001B[32m   1617\u001B[39m     \u001B[38;5;28mself\u001B[39m.options[\u001B[33m\"\u001B[39m\u001B[33mhas_index_names\u001B[39m\u001B[33m\"\u001B[39m] = kwds[\u001B[33m\"\u001B[39m\u001B[33mhas_index_names\u001B[39m\u001B[33m\"\u001B[39m]\n\u001B[32m   1619\u001B[39m \u001B[38;5;28mself\u001B[39m.handles: IOHandles | \u001B[38;5;28;01mNone\u001B[39;00m = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m-> \u001B[39m\u001B[32m1620\u001B[39m \u001B[38;5;28mself\u001B[39m._engine = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_make_engine\u001B[49m\u001B[43m(\u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mengine\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001B[39m, in \u001B[36mTextFileReader._make_engine\u001B[39m\u001B[34m(self, f, engine)\u001B[39m\n\u001B[32m   1878\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[33m\"\u001B[39m\u001B[33mb\u001B[39m\u001B[33m\"\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m mode:\n\u001B[32m   1879\u001B[39m         mode += \u001B[33m\"\u001B[39m\u001B[33mb\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m-> \u001B[39m\u001B[32m1880\u001B[39m \u001B[38;5;28mself\u001B[39m.handles = \u001B[43mget_handle\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   1881\u001B[39m \u001B[43m    \u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1882\u001B[39m \u001B[43m    \u001B[49m\u001B[43mmode\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1883\u001B[39m \u001B[43m    \u001B[49m\u001B[43mencoding\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43moptions\u001B[49m\u001B[43m.\u001B[49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mencoding\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1884\u001B[39m \u001B[43m    \u001B[49m\u001B[43mcompression\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43moptions\u001B[49m\u001B[43m.\u001B[49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mcompression\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1885\u001B[39m \u001B[43m    \u001B[49m\u001B[43mmemory_map\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43moptions\u001B[49m\u001B[43m.\u001B[49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mmemory_map\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1886\u001B[39m \u001B[43m    \u001B[49m\u001B[43mis_text\u001B[49m\u001B[43m=\u001B[49m\u001B[43mis_text\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1887\u001B[39m \u001B[43m    \u001B[49m\u001B[43merrors\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43moptions\u001B[49m\u001B[43m.\u001B[49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mencoding_errors\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mstrict\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1888\u001B[39m \u001B[43m    \u001B[49m\u001B[43mstorage_options\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43moptions\u001B[49m\u001B[43m.\u001B[49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mstorage_options\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1889\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1890\u001B[39m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mself\u001B[39m.handles \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1891\u001B[39m f = \u001B[38;5;28mself\u001B[39m.handles.handle\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\io\\common.py:873\u001B[39m, in \u001B[36mget_handle\u001B[39m\u001B[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001B[39m\n\u001B[32m    868\u001B[39m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(handle, \u001B[38;5;28mstr\u001B[39m):\n\u001B[32m    869\u001B[39m     \u001B[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001B[39;00m\n\u001B[32m    870\u001B[39m     \u001B[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001B[39;00m\n\u001B[32m    871\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m ioargs.encoding \u001B[38;5;129;01mand\u001B[39;00m \u001B[33m\"\u001B[39m\u001B[33mb\u001B[39m\u001B[33m\"\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m ioargs.mode:\n\u001B[32m    872\u001B[39m         \u001B[38;5;66;03m# Encoding\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m873\u001B[39m         handle = \u001B[38;5;28;43mopen\u001B[39;49m\u001B[43m(\u001B[49m\n\u001B[32m    874\u001B[39m \u001B[43m            \u001B[49m\u001B[43mhandle\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    875\u001B[39m \u001B[43m            \u001B[49m\u001B[43mioargs\u001B[49m\u001B[43m.\u001B[49m\u001B[43mmode\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    876\u001B[39m \u001B[43m            \u001B[49m\u001B[43mencoding\u001B[49m\u001B[43m=\u001B[49m\u001B[43mioargs\u001B[49m\u001B[43m.\u001B[49m\u001B[43mencoding\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    877\u001B[39m \u001B[43m            \u001B[49m\u001B[43merrors\u001B[49m\u001B[43m=\u001B[49m\u001B[43merrors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    878\u001B[39m \u001B[43m            \u001B[49m\u001B[43mnewline\u001B[49m\u001B[43m=\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m    879\u001B[39m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    880\u001B[39m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m    881\u001B[39m         \u001B[38;5;66;03m# Binary mode\u001B[39;00m\n\u001B[32m    882\u001B[39m         handle = \u001B[38;5;28mopen\u001B[39m(handle, ioargs.mode)\n",
      "\u001B[31mFileNotFoundError\u001B[39m: [Errno 2] No such file or directory: 'Bird_Strikes_1990_2023.csv'"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nMissing values per column (top 10):\")\n",
    "print(data.isnull().sum().sort_values(ascending=False).head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix categories \n",
    "data.info(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify object-type columns (potential categorical variables)\n",
    "cat_cols = data.select_dtypes(include='object').columns\n",
    "print(\"Possible categorical fields:\", len(cat_cols))\n",
    "print(cat_cols.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.copy()\n",
    "# standardize\n",
    "for col in cat_cols:\n",
    "    data[col] = data[col].astype(str).str.strip()\n",
    "    data[col] = data[col].replace(['nan', 'NaN', 'None', 'UNKNOWN', 'Unknown'], np.nan)\n",
    "\n",
    "# normalize text capitalization for key fields\n",
    "data['STATE'] = data['STATE'].str.upper()\n",
    "data['AIRPORT'] = data['AIRPORT'].str.title()\n",
    "data['SPECIES'] = data['SPECIES'].str.title()\n",
    "data['OPERATOR'] = data['OPERATOR'].str.title()\n",
    "data['PHASE_OF_FLIGHT'] = data['PHASE_OF_FLIGHT'].str.title()\n",
    "data['TIME_OF_DAY'] = data['TIME_OF_DAY'].str.title()\n",
    "data['SIZE'] = data['SIZE'].str.title()\n",
    "data['WARNED'] = data['WARNED'].str.capitalize()\n",
    "\n",
    "\n",
    "for col in ['STATE', 'AIRPORT', 'SPECIES', 'PHASE_OF_FLIGHT', 'TIME_OF_DAY', 'SIZE']:\n",
    "    data[col] = data[col].fillna('Unknown')\n",
    "\n",
    "# convert them to category dtype \n",
    "for col in cat_cols:\n",
    "    data[col] = data[col].astype('category')\n",
    "\n",
    "# take care of dates and times \n",
    "data['TIME'] = pd.to_datetime(data['TIME'], format='%H:%M', errors='coerce').dt.time\n",
    "\n",
    "data['INCIDENT_DATE'] = pd.to_datetime(data['INCIDENT_DATE'], errors='coerce') \n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check changes \n",
    "data.info(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# handling null values \n",
    "# if a column is missing more than 50% of the data, then remove it \n",
    "threshold = len(data) * 0.5\n",
    "data = data.dropna(thresh=threshold, axis=1)\n",
    "print(\"Remaining columns:\", data.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for duplicates \n",
    "data.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['TIME_OF_DAY'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the data has unkonws for time of day even though the the time is known. \n",
    "# Here I define times of the day to the unique categoires of the time of day (dawn,day,dusk,etc.) \n",
    "# to add values in the data that we can directly infer all while maintaining integrity\n",
    "data = data.copy()\n",
    "\n",
    "def infer_time_of_day(t):\n",
    "    if pd.isna(t):\n",
    "        return np.nan\n",
    "    h = t.hour\n",
    "    if 5 <= h < 7:\n",
    "        return 'Dawn'\n",
    "    elif 7 <= h < 18:\n",
    "        return 'Day'\n",
    "    elif 18 <= h < 20:\n",
    "        return 'Dusk'\n",
    "    else:\n",
    "        return 'Night'\n",
    "\n",
    "# Create a new inferred column from TIME\n",
    "data['TIME_OF_DAY_INFERRED'] = data['TIME'].apply(infer_time_of_day)\n",
    "\n",
    "# Replace 'Unknown' only where TIME_OF_DAY is missing or 'Unknown'\n",
    "mask = (data['TIME_OF_DAY'] == 'Unknown') & data['TIME_OF_DAY_INFERRED'].notna()\n",
    "data.loc[mask, 'TIME_OF_DAY'] = data.loc[mask, 'TIME_OF_DAY_INFERRED']\n",
    "\n",
    "# Drop helper column\n",
    "data.drop(columns='TIME_OF_DAY_INFERRED', inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 4 — Hypothesis Testing (30 points)\n",
    "\n",
    "Perform pairwise analysis of select features and evaluate the significance of the pattern or trend. A suitable value for alpha is 5%. Explain all results.\n",
    "\n",
    "Create a scatterplot that shows the relationship between aircraft height and speed. Evaluate the correlation, the strength and the significance of the results.\n",
    "Visualize the distribution of the aircraft speed during: 1) the approach phase of flight and 2) the landing roll phase of flight. Perform a 2 sample t-test and evaluate if there is a statistical difference between the speed during these two flight phases. Tip: if the data is skewed, you will need to address this prior to the statistical analysis.\n",
    "Create a visualization of the aircraft damage grouped by phase of flight.\n",
    "Evaluate if the results are statistically significant. Ensure that you use the appropriate test.\n",
    "Perform ONE (1) additional statistical test.\n",
    "Explain what you are testing and the reason this information is useful.\n",
    "Visualize the data, state the hypothesis and explain if it is statistically significant.\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "sns.set(style=\"whitegrid\")\n",
    "alpha = 0.05\n",
    "df = data.copy()\n",
    "# Normalize\n",
    "for col in ['PHASE_OF_FLIGHT', 'TIME_OF_DAY']:\n",
    " if col in df.columns:\n",
    " df[col] = df[col].astype(str).str.title()\n",
    "if 'SPEED' in df.columns:\n",
    " df['SPEED'] = pd.to_numeric(df['SPEED'], errors='coerce')\n",
    "if 'HEIGHT' in df.columns:\n",
    " df['HEIGHT'] = pd.to_numeric(df['HEIGHT'], errors='coerce')\n",
    "# Part 1\n",
    "if 'HEIGHT' in df.columns and 'SPEED' in df.columns:\n",
    " pair = df[['HEIGHT', 'SPEED']].dropna()\n",
    " if len(pair) > 5:\n",
    " # Scatterplot\n",
    " plt.figure(figsize=(8,6))\n",
    " sns.scatterplot(x='HEIGHT', y='SPEED', data=pair, alpha=0.5)\n",
    " plt.title('Scatterplot: Aircraft Height vs Speed')\n",
    " plt.xlabel('Height (ft)')\n",
    " plt.ylabel('Speed (knots)')\n",
    " plt.tight_layout()\n",
    " plt.show()\n",
    " # Coefficients\n",
    " pearson_r, pearson_p = stats.pearsonr(pair['HEIGHT'], pair['SPEED'])\n",
    " print(f\"Pearson r = {pearson_r:.4f}, p = {pearson_p:.4g}\")\n",
    " print(\"Interpretation:\",\n",
    " \"Strong correlation.\" if abs(pearson_r) > 0.5 else\n",
    " \"Moderate correlation.\" if abs(pearson_r) > 0.3 else\n",
    " \"Weak or negligible correlation.\")\n",
    " if pearson_p < alpha:\n",
    " print(\"Result: Statistically significant relationship (p < 0.05).\")\n",
    " else:\n",
    " print(\"Result: No statistically significant correlation (p ≥ 0.05).\")\n",
    "# Part 2\n",
    "phases = ['Approach', 'Landing Roll']\n",
    "q2 = df[df['PHASE_OF_FLIGHT'].isin(phases)].copy()\n",
    "gA = q2[q2['PHASE_OF_FLIGHT'] == 'Approach']['SPEED'].dropna()\n",
    "gL = q2[q2['PHASE_OF_FLIGHT'] == 'Landing Roll']['SPEED'].dropna()\n",
    "print(f\"Counts — Approach: {len(gA)}, Landing Roll: {len(gL)}\")\n",
    "# Calculate skewness\n",
    "skew_approach = skew(gA)\n",
    "skew_landing = skew(gL)\n",
    "print(f\"Skewness — Approach: {skew_approach:.3f}\")\n",
    "print(f\"Skewness — Landing Roll: {skew_landing:.3f}\")\n",
    "# Visual 1: Histogram\n",
    "plt.figure(figsize=(9,5))\n",
    "sns.histplot(gA, bins=30, stat='density', alpha=0.45, label='Approach', kde=True)\n",
    "sns.histplot(gL, bins=30, stat='density', alpha=0.45, label='Landing Roll', kde=True)\n",
    "plt.title('Distribution of SPEED: Approach vs Landing Roll')\n",
    "plt.xlabel('Speed (knots)')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "# Visual 2: Boxplot\n",
    "plt.figure(figsize=(7,5))\n",
    "sns.boxplot(x='PHASE_OF_FLIGHT', y='SPEED', data=q2, order=['Approach','Landing Roll'])\n",
    "plt.title('SPEED by Phase of Flight')\n",
    "plt.xlabel('Phase of Flight')\n",
    "plt.ylabel('Speed (knots)')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "# 2-sample t-test\n",
    "if len(gA) >= 2 and len(gL) >= 2:\n",
    " t_stat, p_val = stats.ttest_ind(gA, gL, equal_var=False, nan_policy='omit')\n",
    " print(f\"T-test: t = {t_stat:.4f}, p = {p_val:.4g}\")\n",
    " print(f\"Means — Approach: {gA.mean():.2f}, Landing Roll: {gL.mean():.2f}\")\n",
    " print(\"Conclusion:\", \"Significant difference (p < 0.05).\" if p_val < alpha else \"No significant\n",
    "difference (p ≥ 0.05).\")\n",
    "# Part 3\n",
    "# Determine damage column\n",
    "damage_col = None\n",
    "if 'DAMAGE_LEVEL' in df.columns:\n",
    " damage_col = 'DAMAGE_LEVEL'\n",
    "elif 'INDICATED_DAMAGE' in df.columns:\n",
    " damage_col = 'INDICATED_DAMAGE'\n",
    "else:\n",
    " dam_cols = [c for c in df.columns if c.upper().startswith('DAM_')]\n",
    " if dam_cols:\n",
    " df['DamageFlag'] = df[dam_cols].notnull().any(axis=1)\n",
    " damage_col = 'DamageFlag'\n",
    "if damage_col:\n",
    " cont = pd.crosstab(df['PHASE_OF_FLIGHT'], df[damage_col], dropna=False)\n",
    " prop = cont.div(cont.sum(axis=1), axis=0)\n",
    " # Visual: stacked proportion bar\n",
    " ax = prop.plot(kind='bar', stacked=True, figsize=(10,6))\n",
    " ax.set_title(f'Damage ({damage_col}) by Phase of Flight')\n",
    " ax.set_ylabel('Proportion')\n",
    " plt.legend(title=damage_col, bbox_to_anchor=(1.02,1), loc='upper left')\n",
    " plt.tight_layout()\n",
    " plt.show()\n",
    " # Chi-square test\n",
    " chi2, pchi, dof, exp = stats.chi2_contingency(cont.fillna(0))\n",
    " n_total = cont.values.sum()\n",
    " cramers_v = np.sqrt(chi2 / (n_total * (min(cont.shape)-1)))\n",
    " print(f\"Chi-square = {chi2:.4f}, p = {pchi:.4g}, dof = {dof}\")\n",
    " print(f\"Cramer's V = {cramers_v:.4f}\")\n",
    " print(\"Conclusion:\", \"Significant association (p < 0.05).\" if pchi < alpha else \"No significant\n",
    "association (p ≥ 0.05).\")\n",
    "else:\n",
    " print(\"No damage column found — cannot perform Q3.\")\n",
    "# Part 4\n",
    "if 'TIME_OF_DAY' in df.columns and (damage_col or 'DamageFlag' in df.columns):\n",
    " dmg_col = damage_col if damage_col else 'DamageFlag'\n",
    " cont4 = pd.crosstab(df['TIME_OF_DAY'], df[dmg_col])\n",
    " # Visual: Proportion by time of day\n",
    " prop4 = cont4.div(cont4.sum(axis=1), axis=0)\n",
    " ax = prop4.plot(kind='bar', stacked=True, figsize=(9,6))\n",
    " ax.set_title(f'Damage Presence by Time of Day ({dmg_col})')\n",
    " ax.set_ylabel('Proportion')\n",
    " plt.xticks(rotation=25, ha='right')\n",
    " plt.tight_layout()\n",
    " plt.show()\n",
    " # Chi-square test of independence\n",
    " chi4, p4, dof4, exp4 = stats.chi2_contingency(cont4.fillna(0))\n",
    " n4 = cont4.values.sum()\n",
    " cramers_v4 = np.sqrt(chi4 / (n4 * (min(cont4.shape)-1)))\n",
    " print(f\"Chi-square = {chi4:.4f}, p = {p4:.4g}, dof = {dof4}\")\n",
    " print(f\"Cramer's V = {cramers_v4:.4f}\")\n",
    " print(\"Conclusion:\", \"Significant association (p < 0.05).\" if p4 < alpha else \"No significant\n",
    "relationship (p ≥ 0.05).\")"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Question 4 Analysis:\n",
    "1. Here we created a scatterplot that shows the relationship between height of the aircraft in feet\n",
    "and speed of the aircraft in knots during recorded striks. We want to see if the two variables are\n",
    "related and have any correlation. To do this, we conducted a t-test using the pearson r coefficient.\n",
    "Through a python statistics package we calculated an r value between the two variables of\n",
    "0.6960. We then transformed this into a t-test using sample size and degrees of freedom. From\n",
    "that we got a p value of extremely close to zero or just zero. This is less than the alpha of 5%\n",
    "which means the variables are statistically significant and there is a strong correlation. In\n",
    "non-statistical words, height and speed of aircrafts during strike incidents are positvely\n",
    "correlated. As height increases, so does speed duirng strikes. The higher the plane is, the faster it\n",
    "is moving.This can be seen in the visualization. Speed increases shown through the blue dots as\n",
    "does height increases. However, speed seems to be capped because planes cannot go faster than\n",
    "around 250 knots. Additionally, the height is capped around 15,000 ft as the strikes seem to\n",
    "mainly appear below those altitudes where wildlife is more prevalent. In conclsuion, after\n",
    "conducting a t-test we see that height and speed have a strong correlation and statistically\n",
    "significant relationship when it comes to strike incidents\n",
    "2. We compared the distribution of aircraft speed during the approach and landing roll phases of\n",
    "flight. The density and histogram plots show that both distributions are compact, with the landing\n",
    "roll speeds slightly lower than those on approach—consistent with aircraft decelerating after\n",
    "touchdown. The skewness values were 1.449 for approach and –0.615 for landing roll, indicating\n",
    "that approach speeds are moderately right-skewed while landing roll speeds are slightly\n",
    "left-skewed. Despite this, large sample sizes justify using a two-sample t-test, which produced t\n",
    "= 137.38 and p ≈ 0, confirming a statistically significant difference between mean speeds (150.23\n",
    "vs. 105.95 knots). This aligns with operational expectations that aircraft slow considerably once\n",
    "on the runway after landing.\n",
    "3. Here were created a stacked bar chart for each phase of flight. We show the type of damage\n",
    "caused on the aircraft given the phase of flight. We can see that the obvious most common type\n",
    "of damage is N which is none. When planes have strikes, it is most common that no damange is\n",
    "done no matter the phase of flight. We can see that when the plane is en-route or is descent is\n",
    "where we see a higher level of damage during strikes. We conducted a chi square test where we\n",
    "got a value of 5646.9066 and a p value close to zero. This indicates that the relationship is\n",
    "statistically significant meaning that the liklihood of damage is not evenly distributed across all\n",
    "phases of flight. Certain phases such as en-route and descent statisically and graphically show\n",
    "they have different patterns of damage compared to the other phases. However, the cramer V of\n",
    "0.0868, shows that the effect size is small and it is likely that other factors influence the liklihood\n",
    "of damage during strikes.\n",
    "4. Lastly, we performed a chi-square test for comparing time of day of the strikes and damage\n",
    "occured. We created a stacked bar chart showing damage level to aircraft based off time of day.\n",
    "Throught mere examination of that graph we can see that dusk and night time have higher\n",
    "damage levels in the minor and undeterminded categories than the other times of day. We tested\n",
    "this statistically throught a chi square test. We recieve a chi-square of 179.4961 which with an\n",
    "alpha of 5%, correlates to a significant association. This means in words that time of day affects\n",
    "likelihood of damage, supporting what we saw in the visual. This information is useful because it\n",
    "can help identify when strikes are most dangerous, allowing airports and airlines to optimize\n",
    "flight schedules and wildlife mitigation efforts."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
